"createdAt","closedAt","title","url"
"2018-4/12","2018-4/18","Import module error due to missing __init__.py","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/2"
"2018-4/18","2018-4/25","Question: Any plan for Uploading ART to PyPi?","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/3"
"2018-4/30","2018-5/1","error running the examples","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/4"
"2018-6/13","2018-6/14","Keras import should not be commented on utils.py","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/5"
"2018-6/13","2018-6/20","KerasClassifer is not copied when using the PyPl install","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/6"
"2018-6/13","2018-6/19","bug in ""to_categorical"" implementation","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/7"
"2018-6/19","2020-1/8","add a maintainers file","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/8"
"2018-6/29","2018-7/6","Is there any keras wrapper function support to use these attacks with my own model just as cleverhnas and foolbox has???? ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/9"
"2018-7/30","2018-8/23","pytorch 0.4 support","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/12"
"2018-8/10","2018-8/14","need torch to use KerasClassifier","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/13"
"2018-8/10","2018-8/14","can't load imagenet dataset","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/14"
"2018-8/29","2018-11/27","Divide by zero","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/15"
"2018-9/2","2018-9/3","feature_squeezing.py clip_values is wrong","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/16"
"2018-9/4","2018-12/4","Should we use the preprocess for the image in notebooks/attack_defense_imagenet.ipynb ?","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/17"
"2018-9/11","2019-1/8","Getting 12 errors; expected 4","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/18"
"2018-9/20","2019-2/6","the effect of defences methods","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/20"
"2018-10/9","2018-10/10","AssertionError: assert grds.shape == (x_.shape[0], 1) + self.input_shape ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/21"
"2018-10/11","2018-11/27","Run CarliniL2Method on GPU, ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/22"
"2018-10/14","2020-1/28","Models in Caffe","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/23"
"2018-10/30","2018-11/9","Unable to load_model !!!!","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/24"
"2018-11/11","2018-11/27","Defense Algorithm","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/25"
"2018-11/27","2018-11/27","Create templates for issues and feature requests","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/26"
"2019-1/14","2019-2/6","Add a way to set the train/test mode for model explicitly for prediction and adversarial crafting","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/28"
"2019-1/23","2019-1/23","IndexError in CarliniL2Method","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/29"
"2019-1/25","2019-2/13","Add logging usage in examples and wiki","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/31"
"2019-2/4","2019-2/6","Matrix comatiblity issue","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/32"
"2019-2/7","2019-7/13","ART does not work with Keras Embedding layers","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/33"
"2019-2/14","2019-4/1","Improve design for expectation over transformations (EoT) integration with attacks","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/36"
"2019-2/21","2019-7/13","Adapt values for attack parameters to better defaults","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/37"
"2019-3/6","2019-3/12","Remove `Detector` abstract class and edit detectors to extend `Classifier`","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/38"
"2019-3/7","2019-9/12","Implement Pickle capacities for classifiers","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/39"
"2019-3/28","2019-3/30","Generate Spatial Transformation attack ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/40"
"2019-3/29","2019-3/29","Error when running FGSM with pretrained ResNet50 in Keras","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/41"
"2019-4/14","2019-4/17",".travis.yml: The 'sudo' tag is now deprecated in Travis CI","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/46"
"2019-4/17","2019-9/12","Add support for scikit-learn models","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/47"
"2019-4/19","2019-7/8","Adapt ART to feature vectors","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/49"
"2019-4/19","2019-7/24","Adapt ART to other types of models than neural networks","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/50"
"2019-4/22","2020-12/1","Implement low frequency adversarial perturbation strategy","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/51"
"2019-4/24","2019-4/26","Refactor computations required for logging","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/54"
"2019-4/26","2019-5/14","Rename all test files to `*_tests.py`","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/58"
"2019-4/29","2019-6/2","Create example notebook investigating the performance of boundary attack","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/59"
"2019-4/30","2020-12/1","Error in Zoo attack","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/60"
"2019-5/2","2019-7/13","Investigate models that were corrupted by git LFS","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/63"
"2019-5/14","2021-9/25","Consistency error with wrappers when reusing a classifier","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/65"
"2019-5/14","2019-9/12","Tensorflow 2.0 Support","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/66"
"2019-5/14","2019-6/2","Can't attack model with model with customized layers","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/67"
"2019-5/17","2019-5/24","Minimise calls to method predict in attacks FastGradientMethod and BasicIterativeMethod","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/70"
"2019-5/20","2019-5/24","Incorrect computation of perturbation budget in BIM / PGD with random init","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/73"
"2019-5/22","2019-7/23","The loss_gradient of PyTorch should be carried on logits instead of softmax outputs","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/75"
"2019-5/22","2019-5/22","GPU capability for keras classifier","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/76"
"2019-5/23","2019-5/29","Adversarial Patch size problem","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/77"
"2019-5/29","2019-7/13","Implement attack: ""Boundary Attack++: Query-Efficient Decision-Based Adversarial Attack""","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/80"
"2019-5/29","null","Check Boundary Attack initialised with target class","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/81"
"2019-5/30","2019-7/13","Sunset Support for Python2","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/83"
"2019-5/31","2019-7/13","Compatibility of defence JpegCompression with classifier's preprocessing (standardisation)","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/84"
"2019-6/5","2019-6/8","PGD and BIM are not correctly accounting for eps on branch dev","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/85"
"2019-6/6","2020-6/15","Implement progress bar in ART","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/87"
"2019-6/7","2019-7/13","adversarial-training-mnist.ipynb does not able to read the mnist_cnn_original.h5","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/88"
"2019-6/7","2019-7/13","PyTorch adversarial attack strange behavior ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/89"
"2019-6/10","2019-7/13","Change Basic Iterative Method (BIM)","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/90"
"2019-6/19","2019-7/13","Update unit testing versions of Tensorflow","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/94"
"2019-6/19","2019-7/13","Travis reports job passing although unit tests failed","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/95"
"2019-6/21","2019-7/13","Unnecessary calculation of gradient of all instances in Adversarial Patch","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/96"
"2019-7/3","2019-7/5","Carlini methods do not affect the images [Keras/Tensorflow]","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/101"
"2019-7/8","2019-7/13","Apply batch_size of attack to classifier.","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/105"
"2019-7/8","2019-7/23","Generalize Pytorchclassifier to support loss function on logit","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/106"
"2019-7/8","2019-7/13","Update (path to) imagenet labels in notebook attack_defense_imagenet","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/109"
"2019-7/15","2019-9/12","Adding Randomized Smoothing functionality","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/114"
"2019-7/16","2019-9/12","Implement decision tree attack by Papernot et al. (https://arxiv.org/abs/1605.07277)","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/115"
"2019-7/16","2019-9/12","Implement attack on Gaussian Processes (https://arxiv.org/abs/1812.02606).","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/116"
"2019-7/20","2019-9/12","Invalid values in KL divergence computation of VAT","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/120"
"2019-7/26","2019-9/12","Create new ART classifier for remote models","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/123"
"2019-7/30","2019-9/12","Add robustness verification/metric for tree-based classifiers","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/124"
"2019-7/31","2019-9/12","Incompatibility between ART API for DataGenerators and standard PyTorch data loaders","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/126"
"2019-8/1","2019-8/1","HopSkipJump is very slow when attacking pytorch models","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/127"
"2019-8/2","2019-8/5","Pytorch examples","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/128"
"2019-8/5","2019-8/5","mnist_transferability example error","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/130"
"2019-8/8","2019-8/8","mnist_poison_detection.py example error","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/133"
"2019-8/13","2020-1/6","Add descriptions and references on limitations of implemented defences","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/137"
"2019-8/15","2019-9/12","Variable prediction output when learning parameter is set in keras classifiers","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/138"
"2019-8/17","2019-9/12","Examples Readme.md not up to date","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/140"
"2019-8/21","2019-9/12","Any examples for art.metrics?","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/141"
"2019-8/22","2019-8/23","Classifier model parameter not trained.","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/142"
"2019-8/29","2019-8/29","clipping of adversarial examples missing in PGD attack","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/148"
"2019-9/5","2019-9/12","Add black box example for Tesseract OCR ","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/152"
"2019-9/9","2019-9/12","Investigate vector support issue with VAT","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/157"
"2019-9/24","2019-10/8","ART Classifier doesn't work with Binary Logistic Regression","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/171"
"2019-9/28","2019-10/6","Bug in box intersection","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/173"
"2019-9/28","2019-10/8","Extend exception message of checks of classifier/attack compatibility to provide better/more detailed explanation","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/174"
"2019-9/30","2020-1/8","Add Support for Keras >= 2.3.0","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/176"
"2019-10/11","2020-3/15","Unexpected value for 'assignment' variable in poisoning defense evaluation","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/186"
"2019-10/14","2020-1/8","Implement class_gradients method for art.classifiers.ScikitlearnSVC","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/187"
"2019-10/21","2020-1/8","No consensus in reporting success rate of an attack","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/188"
"2019-10/25","2020-1/8","Native logging is broken with ART 1.0.1","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/189"
"2019-10/30","2021-3/16","Explore and Implement Model Extraction Attacks and Defences","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/191"
"2019-10/31","2020-1/8","What changed with DeepFool in 1.0.0?","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/192"
"2019-11/1","2020-1/8","EOFError: Ran out of input","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/194"
"2019-11/1","2019-11/4","Potential Bug in JSMA implementation","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/196"
"2019-11/2","2020-1/8","ART attacks with Tensorflow-GPU support","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/197"
"2019-11/4","2020-1/8","empirical robustness metric: HopSkipJump attack support","https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/198"
