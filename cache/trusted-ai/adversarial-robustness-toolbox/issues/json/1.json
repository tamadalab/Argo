{
    "data": {
        "repository": {
            "issues": {
                "totalCount": 802,
                "nodes": [
                    {
                        "title": "Import module error due to missing __init__.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/2",
                        "createdAt": "2018-04-12T19:10:31Z",
                        "closedAt": "2018-04-18T21:25:21Z"
                    },
                    {
                        "title": "Question: Any plan for Uploading ART to PyPi?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/3",
                        "createdAt": "2018-04-18T22:42:50Z",
                        "closedAt": "2018-04-25T21:59:37Z"
                    },
                    {
                        "title": "error running the examples",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/4",
                        "createdAt": "2018-04-30T16:42:16Z",
                        "closedAt": "2018-05-01T13:25:10Z"
                    },
                    {
                        "title": "Keras import should not be commented on utils.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/5",
                        "createdAt": "2018-06-13T07:51:43Z",
                        "closedAt": "2018-06-14T13:25:00Z"
                    },
                    {
                        "title": "KerasClassifer is not copied when using the PyPl install",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/6",
                        "createdAt": "2018-06-13T07:53:12Z",
                        "closedAt": "2018-06-20T10:11:15Z"
                    },
                    {
                        "title": "bug in \"to_categorical\" implementation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/7",
                        "createdAt": "2018-06-13T09:23:45Z",
                        "closedAt": "2018-06-19T15:46:46Z"
                    },
                    {
                        "title": "add a maintainers file",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/8",
                        "createdAt": "2018-06-19T14:21:13Z",
                        "closedAt": "2020-01-08T00:06:04Z"
                    },
                    {
                        "title": "Is there any keras wrapper function support to use these attacks with my own model just as cleverhnas and foolbox has???? ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/9",
                        "createdAt": "2018-06-29T16:13:06Z",
                        "closedAt": "2018-07-06T10:28:23Z"
                    },
                    {
                        "title": "pytorch 0.4 support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/12",
                        "createdAt": "2018-07-30T13:13:30Z",
                        "closedAt": "2018-08-23T17:29:18Z"
                    },
                    {
                        "title": "need torch to use KerasClassifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/13",
                        "createdAt": "2018-08-10T09:43:16Z",
                        "closedAt": "2018-08-14T13:50:13Z"
                    },
                    {
                        "title": "can't load imagenet dataset",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/14",
                        "createdAt": "2018-08-10T10:39:13Z",
                        "closedAt": "2018-08-14T13:50:13Z"
                    },
                    {
                        "title": "Divide by zero",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/15",
                        "createdAt": "2018-08-29T10:23:48Z",
                        "closedAt": "2018-11-27T11:32:09Z"
                    },
                    {
                        "title": "feature_squeezing.py clip_values is wrong",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/16",
                        "createdAt": "2018-09-02T12:39:02Z",
                        "closedAt": "2018-09-03T14:42:12Z"
                    },
                    {
                        "title": "Should we use the preprocess for the image in notebooks/attack_defense_imagenet.ipynb ?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/17",
                        "createdAt": "2018-09-04T14:45:42Z",
                        "closedAt": "2018-12-04T17:35:02Z"
                    },
                    {
                        "title": "Getting 12 errors; expected 4",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/18",
                        "createdAt": "2018-09-11T17:05:46Z",
                        "closedAt": "2019-01-08T16:03:57Z"
                    },
                    {
                        "title": "the effect of defences methods",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/20",
                        "createdAt": "2018-09-20T14:30:57Z",
                        "closedAt": "2019-02-06T15:21:33Z"
                    },
                    {
                        "title": "AssertionError: assert grds.shape == (x_.shape[0], 1) + self.input_shape ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/21",
                        "createdAt": "2018-10-09T19:42:27Z",
                        "closedAt": "2018-10-10T15:07:12Z"
                    },
                    {
                        "title": "Run CarliniL2Method on GPU, ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/22",
                        "createdAt": "2018-10-11T22:58:06Z",
                        "closedAt": "2018-11-27T11:31:23Z"
                    },
                    {
                        "title": "Models in Caffe",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/23",
                        "createdAt": "2018-10-14T11:35:14Z",
                        "closedAt": "2020-01-28T13:44:09Z"
                    },
                    {
                        "title": "Unable to load_model !!!!",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/24",
                        "createdAt": "2018-10-30T16:14:52Z",
                        "closedAt": "2018-11-09T11:03:42Z"
                    },
                    {
                        "title": "Defense Algorithm",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/25",
                        "createdAt": "2018-11-11T17:01:02Z",
                        "closedAt": "2018-11-27T11:33:00Z"
                    },
                    {
                        "title": "Create templates for issues and feature requests",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/26",
                        "createdAt": "2018-11-27T11:37:52Z",
                        "closedAt": "2018-11-27T11:38:21Z"
                    },
                    {
                        "title": "Add a way to set the train/test mode for model explicitly for prediction and adversarial crafting",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/28",
                        "createdAt": "2019-01-14T15:38:55Z",
                        "closedAt": "2019-02-06T15:20:56Z"
                    },
                    {
                        "title": "IndexError in CarliniL2Method",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/29",
                        "createdAt": "2019-01-23T01:49:59Z",
                        "closedAt": "2019-01-23T11:55:36Z"
                    },
                    {
                        "title": "Add logging usage in examples and wiki",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/31",
                        "createdAt": "2019-01-25T16:44:45Z",
                        "closedAt": "2019-02-13T11:45:20Z"
                    },
                    {
                        "title": "Matrix comatiblity issue",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/32",
                        "createdAt": "2019-02-04T09:25:45Z",
                        "closedAt": "2019-02-06T15:32:17Z"
                    },
                    {
                        "title": "ART does not work with Keras Embedding layers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/33",
                        "createdAt": "2019-02-07T00:29:05Z",
                        "closedAt": "2019-07-13T00:11:48Z"
                    },
                    {
                        "title": "Improve design for expectation over transformations (EoT) integration with attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/36",
                        "createdAt": "2019-02-14T10:54:23Z",
                        "closedAt": "2019-04-01T10:31:13Z"
                    },
                    {
                        "title": "Adapt values for attack parameters to better defaults",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/37",
                        "createdAt": "2019-02-21T11:59:15Z",
                        "closedAt": "2019-07-13T00:11:17Z"
                    },
                    {
                        "title": "Remove `Detector` abstract class and edit detectors to extend `Classifier`",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/38",
                        "createdAt": "2019-03-06T16:09:24Z",
                        "closedAt": "2019-03-12T21:17:48Z"
                    },
                    {
                        "title": "Implement Pickle capacities for classifiers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/39",
                        "createdAt": "2019-03-07T15:51:04Z",
                        "closedAt": "2019-09-12T19:49:18Z"
                    },
                    {
                        "title": "Generate Spatial Transformation attack ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/40",
                        "createdAt": "2019-03-28T16:03:54Z",
                        "closedAt": "2019-03-30T07:30:31Z"
                    },
                    {
                        "title": "Error when running FGSM with pretrained ResNet50 in Keras",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/41",
                        "createdAt": "2019-03-29T13:59:19Z",
                        "closedAt": "2019-03-29T15:17:39Z"
                    },
                    {
                        "title": ".travis.yml: The 'sudo' tag is now deprecated in Travis CI",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/46",
                        "createdAt": "2019-04-14T13:20:17Z",
                        "closedAt": "2019-04-17T14:28:57Z"
                    },
                    {
                        "title": "Add support for scikit-learn models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/47",
                        "createdAt": "2019-04-17T15:54:27Z",
                        "closedAt": "2019-09-12T20:08:54Z"
                    },
                    {
                        "title": "Adapt ART to feature vectors",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/49",
                        "createdAt": "2019-04-19T16:32:44Z",
                        "closedAt": "2019-07-08T19:52:59Z"
                    },
                    {
                        "title": "Adapt ART to other types of models than neural networks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/50",
                        "createdAt": "2019-04-19T17:04:00Z",
                        "closedAt": "2019-07-24T13:41:16Z"
                    },
                    {
                        "title": "Implement low frequency adversarial perturbation strategy",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/51",
                        "createdAt": "2019-04-22T10:08:18Z",
                        "closedAt": "2020-12-01T12:54:02Z"
                    },
                    {
                        "title": "Refactor computations required for logging",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/54",
                        "createdAt": "2019-04-24T16:00:19Z",
                        "closedAt": "2019-04-26T14:08:42Z"
                    },
                    {
                        "title": "Rename all test files to `*_tests.py`",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/58",
                        "createdAt": "2019-04-26T14:33:39Z",
                        "closedAt": "2019-05-14T15:26:53Z"
                    },
                    {
                        "title": "Create example notebook investigating the performance of boundary attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/59",
                        "createdAt": "2019-04-29T10:47:39Z",
                        "closedAt": "2019-06-02T11:21:36Z"
                    },
                    {
                        "title": "Error in Zoo attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/60",
                        "createdAt": "2019-04-30T15:34:41Z",
                        "closedAt": "2020-12-01T12:52:48Z"
                    },
                    {
                        "title": "Investigate models that were corrupted by git LFS",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/63",
                        "createdAt": "2019-05-02T14:48:01Z",
                        "closedAt": "2019-07-13T00:02:05Z"
                    },
                    {
                        "title": "Consistency error with wrappers when reusing a classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/65",
                        "createdAt": "2019-05-14T10:06:36Z",
                        "closedAt": "2021-09-25T23:37:35Z"
                    },
                    {
                        "title": "Tensorflow 2.0 Support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/66",
                        "createdAt": "2019-05-14T14:31:55Z",
                        "closedAt": "2019-09-12T19:44:26Z"
                    },
                    {
                        "title": "Can't attack model with model with customized layers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/67",
                        "createdAt": "2019-05-14T15:32:06Z",
                        "closedAt": "2019-06-02T19:20:41Z"
                    },
                    {
                        "title": "Minimise calls to method predict in attacks FastGradientMethod and BasicIterativeMethod",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/70",
                        "createdAt": "2019-05-17T10:11:50Z",
                        "closedAt": "2019-05-24T07:49:55Z"
                    },
                    {
                        "title": "Incorrect computation of perturbation budget in BIM / PGD with random init",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/73",
                        "createdAt": "2019-05-20T15:35:42Z",
                        "closedAt": "2019-05-24T07:49:33Z"
                    },
                    {
                        "title": "The loss_gradient of PyTorch should be carried on logits instead of softmax outputs",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/75",
                        "createdAt": "2019-05-22T06:59:56Z",
                        "closedAt": "2019-07-23T20:34:41Z"
                    },
                    {
                        "title": "GPU capability for keras classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/76",
                        "createdAt": "2019-05-22T13:02:32Z",
                        "closedAt": "2019-05-22T13:35:32Z"
                    },
                    {
                        "title": "Adversarial Patch size problem",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/77",
                        "createdAt": "2019-05-23T17:00:27Z",
                        "closedAt": "2019-05-29T07:32:54Z"
                    },
                    {
                        "title": "Implement attack: \"Boundary Attack++: Query-Efficient Decision-Based Adversarial Attack\"",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/80",
                        "createdAt": "2019-05-29T16:17:26Z",
                        "closedAt": "2019-07-13T19:43:31Z"
                    },
                    {
                        "title": "Check Boundary Attack initialised with target class",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/81",
                        "createdAt": "2019-05-29T16:21:52Z",
                        "closedAt": null
                    },
                    {
                        "title": "Sunset Support for Python2",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/83",
                        "createdAt": "2019-05-30T13:53:25Z",
                        "closedAt": "2019-07-13T00:09:59Z"
                    },
                    {
                        "title": "Compatibility of defence JpegCompression with classifier's preprocessing (standardisation)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/84",
                        "createdAt": "2019-05-31T19:57:15Z",
                        "closedAt": "2019-07-13T00:09:46Z"
                    },
                    {
                        "title": "PGD and BIM are not correctly accounting for eps on branch dev",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/85",
                        "createdAt": "2019-06-05T13:41:39Z",
                        "closedAt": "2019-06-08T17:22:09Z"
                    },
                    {
                        "title": "Implement progress bar in ART",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/87",
                        "createdAt": "2019-06-06T15:20:41Z",
                        "closedAt": "2020-06-15T20:46:11Z"
                    },
                    {
                        "title": "adversarial-training-mnist.ipynb does not able to read the mnist_cnn_original.h5",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/88",
                        "createdAt": "2019-06-07T01:19:24Z",
                        "closedAt": "2019-07-13T00:02:05Z"
                    },
                    {
                        "title": "PyTorch adversarial attack strange behavior ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/89",
                        "createdAt": "2019-06-07T17:39:45Z",
                        "closedAt": "2019-07-13T19:39:04Z"
                    },
                    {
                        "title": "Change Basic Iterative Method (BIM)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/90",
                        "createdAt": "2019-06-10T20:00:43Z",
                        "closedAt": "2019-07-13T00:02:05Z"
                    },
                    {
                        "title": "Update unit testing versions of Tensorflow",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/94",
                        "createdAt": "2019-06-19T12:40:36Z",
                        "closedAt": "2019-07-13T00:09:07Z"
                    },
                    {
                        "title": "Travis reports job passing although unit tests failed",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/95",
                        "createdAt": "2019-06-19T20:44:06Z",
                        "closedAt": "2019-07-13T00:02:05Z"
                    },
                    {
                        "title": "Unnecessary calculation of gradient of all instances in Adversarial Patch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/96",
                        "createdAt": "2019-06-21T11:51:21Z",
                        "closedAt": "2019-07-13T00:02:06Z"
                    },
                    {
                        "title": "Carlini methods do not affect the images [Keras/Tensorflow]",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/101",
                        "createdAt": "2019-07-03T14:59:14Z",
                        "closedAt": "2019-07-05T08:58:25Z"
                    },
                    {
                        "title": "Apply batch_size of attack to classifier.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/105",
                        "createdAt": "2019-07-08T12:47:18Z",
                        "closedAt": "2019-07-13T00:08:52Z"
                    },
                    {
                        "title": "Generalize Pytorchclassifier to support loss function on logit",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/106",
                        "createdAt": "2019-07-08T12:59:48Z",
                        "closedAt": "2019-07-23T20:36:42Z"
                    },
                    {
                        "title": "Update (path to) imagenet labels in notebook attack_defense_imagenet",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/109",
                        "createdAt": "2019-07-08T16:38:29Z",
                        "closedAt": "2019-07-13T00:08:29Z"
                    },
                    {
                        "title": "Adding Randomized Smoothing functionality",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/114",
                        "createdAt": "2019-07-15T13:02:40Z",
                        "closedAt": "2019-09-12T19:48:11Z"
                    },
                    {
                        "title": "Implement decision tree attack by Papernot et al. (https://arxiv.org/abs/1605.07277)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/115",
                        "createdAt": "2019-07-16T14:10:48Z",
                        "closedAt": "2019-09-12T19:56:21Z"
                    },
                    {
                        "title": "Implement attack on Gaussian Processes (https://arxiv.org/abs/1812.02606).",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/116",
                        "createdAt": "2019-07-16T14:13:11Z",
                        "closedAt": "2019-09-12T19:59:18Z"
                    },
                    {
                        "title": "Invalid values in KL divergence computation of VAT",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/120",
                        "createdAt": "2019-07-20T10:30:11Z",
                        "closedAt": "2019-09-12T20:07:58Z"
                    },
                    {
                        "title": "Create new ART classifier for remote models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/123",
                        "createdAt": "2019-07-26T09:59:44Z",
                        "closedAt": "2019-09-12T20:19:28Z"
                    },
                    {
                        "title": "Add robustness verification/metric for tree-based classifiers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/124",
                        "createdAt": "2019-07-30T21:13:01Z",
                        "closedAt": "2019-09-12T20:03:17Z"
                    },
                    {
                        "title": "Incompatibility between ART API for DataGenerators and standard PyTorch data loaders",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/126",
                        "createdAt": "2019-07-31T21:14:41Z",
                        "closedAt": "2019-09-12T20:06:06Z"
                    },
                    {
                        "title": "HopSkipJump is very slow when attacking pytorch models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/127",
                        "createdAt": "2019-08-01T08:15:59Z",
                        "closedAt": "2019-08-01T21:52:39Z"
                    },
                    {
                        "title": "Pytorch examples",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/128",
                        "createdAt": "2019-08-02T20:01:19Z",
                        "closedAt": "2019-08-05T19:36:43Z"
                    },
                    {
                        "title": "mnist_transferability example error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/130",
                        "createdAt": "2019-08-05T15:43:20Z",
                        "closedAt": "2019-08-05T17:57:56Z"
                    },
                    {
                        "title": "mnist_poison_detection.py example error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/133",
                        "createdAt": "2019-08-08T03:03:25Z",
                        "closedAt": "2019-08-08T13:58:04Z"
                    },
                    {
                        "title": "Add descriptions and references on limitations of implemented defences",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/137",
                        "createdAt": "2019-08-13T16:37:10Z",
                        "closedAt": "2020-01-06T13:27:59Z"
                    },
                    {
                        "title": "Variable prediction output when learning parameter is set in keras classifiers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/138",
                        "createdAt": "2019-08-15T15:49:21Z",
                        "closedAt": "2019-09-12T20:07:08Z"
                    },
                    {
                        "title": "Examples Readme.md not up to date",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/140",
                        "createdAt": "2019-08-17T14:55:59Z",
                        "closedAt": "2019-09-12T20:03:37Z"
                    },
                    {
                        "title": "Any examples for art.metrics?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/141",
                        "createdAt": "2019-08-21T02:54:28Z",
                        "closedAt": "2019-09-12T20:03:49Z"
                    },
                    {
                        "title": "Classifier model parameter not trained.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/142",
                        "createdAt": "2019-08-22T21:49:33Z",
                        "closedAt": "2019-08-23T02:30:03Z"
                    },
                    {
                        "title": "clipping of adversarial examples missing in PGD attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/148",
                        "createdAt": "2019-08-29T10:59:30Z",
                        "closedAt": "2019-08-29T21:55:02Z"
                    },
                    {
                        "title": "Add black box example for Tesseract OCR ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/152",
                        "createdAt": "2019-09-05T19:12:40Z",
                        "closedAt": "2019-09-12T20:15:02Z"
                    },
                    {
                        "title": "Investigate vector support issue with VAT",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/157",
                        "createdAt": "2019-09-09T09:21:24Z",
                        "closedAt": "2019-09-12T19:53:35Z"
                    },
                    {
                        "title": "ART Classifier doesn't work with Binary Logistic Regression",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/171",
                        "createdAt": "2019-09-24T16:51:39Z",
                        "closedAt": "2019-10-08T14:37:18Z"
                    },
                    {
                        "title": "Bug in box intersection",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/173",
                        "createdAt": "2019-09-28T02:57:17Z",
                        "closedAt": "2019-10-06T07:26:05Z"
                    },
                    {
                        "title": "Extend exception message of checks of classifier/attack compatibility to provide better/more detailed explanation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/174",
                        "createdAt": "2019-09-28T06:25:12Z",
                        "closedAt": "2019-10-08T09:44:30Z"
                    },
                    {
                        "title": "Add Support for Keras >= 2.3.0",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/176",
                        "createdAt": "2019-09-30T20:54:10Z",
                        "closedAt": "2020-01-08T01:23:23Z"
                    },
                    {
                        "title": "Unexpected value for 'assignment' variable in poisoning defense evaluation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/186",
                        "createdAt": "2019-10-11T01:56:01Z",
                        "closedAt": "2020-03-15T20:06:06Z"
                    },
                    {
                        "title": "Implement class_gradients method for art.classifiers.ScikitlearnSVC",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/187",
                        "createdAt": "2019-10-14T12:16:13Z",
                        "closedAt": "2020-01-08T01:25:13Z"
                    },
                    {
                        "title": "No consensus in reporting success rate of an attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/188",
                        "createdAt": "2019-10-21T02:07:03Z",
                        "closedAt": "2020-01-08T01:25:30Z"
                    },
                    {
                        "title": "Native logging is broken with ART 1.0.1",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/189",
                        "createdAt": "2019-10-25T02:45:54Z",
                        "closedAt": "2020-01-08T01:23:43Z"
                    },
                    {
                        "title": "Explore and Implement Model Extraction Attacks and Defences",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/191",
                        "createdAt": "2019-10-30T00:22:07Z",
                        "closedAt": "2021-03-16T17:59:23Z"
                    },
                    {
                        "title": "What changed with DeepFool in 1.0.0?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/192",
                        "createdAt": "2019-10-31T15:04:25Z",
                        "closedAt": "2020-01-08T01:23:11Z"
                    },
                    {
                        "title": "EOFError: Ran out of input",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/194",
                        "createdAt": "2019-11-01T04:55:39Z",
                        "closedAt": "2020-01-08T01:21:22Z"
                    },
                    {
                        "title": "Potential Bug in JSMA implementation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/196",
                        "createdAt": "2019-11-01T19:23:26Z",
                        "closedAt": "2019-11-04T22:37:15Z"
                    },
                    {
                        "title": "ART attacks with Tensorflow-GPU support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/197",
                        "createdAt": "2019-11-02T16:16:54Z",
                        "closedAt": "2020-01-08T01:21:36Z"
                    },
                    {
                        "title": "empirical robustness metric: HopSkipJump attack support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/198",
                        "createdAt": "2019-11-04T11:26:14Z",
                        "closedAt": "2020-01-08T01:25:49Z"
                    }
                ],
                "pageInfo": {
                    "endCursor": "Y3Vyc29yOnYyOpHOHtItvQ==",
                    "hasNextPage": true
                }
            }
        }
    }
}