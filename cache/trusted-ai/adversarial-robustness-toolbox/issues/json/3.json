{
    "data": {
        "repository": {
            "issues": {
                "totalCount": 802,
                "nodes": [
                    {
                        "title": "Question about using HopSkipJump and BlackboxClassifer for Tesseract",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/380",
                        "createdAt": "2020-04-18T19:07:59Z",
                        "closedAt": "2020-05-01T14:32:43Z"
                    },
                    {
                        "title": "JSMA weird behavior",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/382",
                        "createdAt": "2020-04-19T05:31:09Z",
                        "closedAt": "2020-06-15T20:40:07Z"
                    },
                    {
                        "title": "Trouble visualizing RGB images using Activation Defence",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/387",
                        "createdAt": "2020-04-21T21:09:12Z",
                        "closedAt": "2020-04-23T21:53:20Z"
                    },
                    {
                        "title": "Support for targeted attacks for Universal Perturbation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/393",
                        "createdAt": "2020-04-27T19:39:37Z",
                        "closedAt": "2020-08-07T20:43:11Z"
                    },
                    {
                        "title": "Resampling preprocessor defense",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/394",
                        "createdAt": "2020-04-28T12:34:34Z",
                        "closedAt": "2020-06-15T20:39:39Z"
                    },
                    {
                        "title": "attack_decision_based_boundary.ipynb seems not to consider preprocessing regarding ImageNet correctly.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/395",
                        "createdAt": "2020-04-29T03:59:05Z",
                        "closedAt": "2020-05-04T13:31:11Z"
                    },
                    {
                        "title": "Spectral Signature Backdoor Poisoning Defense",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/396",
                        "createdAt": "2020-04-29T21:07:52Z",
                        "closedAt": "2020-06-15T20:39:02Z"
                    },
                    {
                        "title": "Possible bug when loading PyTorch model.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/401",
                        "createdAt": "2020-05-01T20:23:18Z",
                        "closedAt": "2020-05-01T21:04:24Z"
                    },
                    {
                        "title": "Allow pip to install ART with the full set of required and optional dependencies",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/405",
                        "createdAt": "2020-05-06T16:00:32Z",
                        "closedAt": "2020-06-15T20:43:15Z"
                    },
                    {
                        "title": "Implement Wasserstein distance as a new metric",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/407",
                        "createdAt": "2020-05-06T22:23:33Z",
                        "closedAt": "2020-06-15T20:38:37Z"
                    },
                    {
                        "title": "Video preprocessor defenses",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/408",
                        "createdAt": "2020-05-07T18:05:09Z",
                        "closedAt": "2020-06-15T20:38:27Z"
                    },
                    {
                        "title": "ImportError: cannot import name 'ART_DATA_PATH'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/413",
                        "createdAt": "2020-05-14T00:07:39Z",
                        "closedAt": "2020-05-14T00:42:43Z"
                    },
                    {
                        "title": "Adversarial Trainer progress bar",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/418",
                        "createdAt": "2020-05-18T16:56:56Z",
                        "closedAt": "2020-06-15T20:37:56Z"
                    },
                    {
                        "title": "Two questions about Functionally Equivalent Extraction",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/420",
                        "createdAt": "2020-05-19T15:35:56Z",
                        "closedAt": "2020-06-15T20:37:43Z"
                    },
                    {
                        "title": "Replace `channel_index` with `channels_first` argument.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/423",
                        "createdAt": "2020-05-22T13:23:48Z",
                        "closedAt": "2020-06-15T20:36:12Z"
                    },
                    {
                        "title": "Keras: cannot identify custom loss function name/type",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/427",
                        "createdAt": "2020-05-26T08:26:06Z",
                        "closedAt": "2020-06-15T20:36:00Z"
                    },
                    {
                        "title": "Can we generate attacks for multiple-output models.? ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/430",
                        "createdAt": "2020-05-27T08:58:27Z",
                        "closedAt": "2020-06-15T20:35:47Z"
                    },
                    {
                        "title": "Default values of some preprocessors may confuse users.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/434",
                        "createdAt": "2020-05-30T05:37:05Z",
                        "closedAt": "2020-06-02T02:52:57Z"
                    },
                    {
                        "title": "Boundary attack overflows on Xception network and stops working",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/436",
                        "createdAt": "2020-06-02T22:46:44Z",
                        "closedAt": "2020-06-04T15:07:36Z"
                    },
                    {
                        "title": "Implement Carlini & Wagner L_0 Attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/443",
                        "createdAt": "2020-06-07T17:35:14Z",
                        "closedAt": "2021-06-15T22:19:53Z"
                    },
                    {
                        "title": "Improve PyTorch classifier predict speed by not calculating gradients",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/448",
                        "createdAt": "2020-06-09T22:26:08Z",
                        "closedAt": "2020-06-12T16:12:54Z"
                    },
                    {
                        "title": "Thermometer encoding usage",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/450",
                        "createdAt": "2020-06-09T22:48:23Z",
                        "closedAt": "2020-06-15T20:35:30Z"
                    },
                    {
                        "title": "wildcard in loss_gradient function",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/457",
                        "createdAt": "2020-06-10T22:08:43Z",
                        "closedAt": "2020-06-15T20:34:43Z"
                    },
                    {
                        "title": "Replace Classifier None If statements with NotImplemented Warning pytests reports",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/459",
                        "createdAt": "2020-06-11T13:33:53Z",
                        "closedAt": "2020-10-06T09:35:20Z"
                    },
                    {
                        "title": "Move all tests under the framework agnostic loop",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/460",
                        "createdAt": "2020-06-11T13:37:12Z",
                        "closedAt": "2020-09-20T22:54:59Z"
                    },
                    {
                        "title": "Create Wiki page to describe how to create framework agnostic ART tests",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/461",
                        "createdAt": "2020-06-11T13:38:51Z",
                        "closedAt": "2020-08-21T14:15:43Z"
                    },
                    {
                        "title": "Treat Tensorflow1 and Tensorflow2 as two separate framework in tests",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/462",
                        "createdAt": "2020-06-11T13:41:39Z",
                        "closedAt": "2020-10-28T10:42:07Z"
                    },
                    {
                        "title": "Enable batches with variable length/size inputs ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/464",
                        "createdAt": "2020-06-11T21:27:19Z",
                        "closedAt": null
                    },
                    {
                        "title": "Allow norm to be passed to attacks as string argument",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/465",
                        "createdAt": "2020-06-11T21:49:51Z",
                        "closedAt": "2020-09-20T22:55:04Z"
                    },
                    {
                        "title": "Extend ProjectedGradientDescent for PyTorch with option for apex",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/471",
                        "createdAt": "2020-06-17T10:40:57Z",
                        "closedAt": "2020-12-01T12:15:13Z"
                    },
                    {
                        "title": "Implement Fast is Better than Free protocol for TensorFlow v2",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/472",
                        "createdAt": "2020-06-17T10:43:38Z",
                        "closedAt": null
                    },
                    {
                        "title": "Define APIs and implement prototypes for Federated Learning",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/473",
                        "createdAt": "2020-06-17T10:46:46Z",
                        "closedAt": "2020-12-01T12:32:42Z"
                    },
                    {
                        "title": "LightGBM Tutorial",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/474",
                        "createdAt": "2020-06-18T23:22:17Z",
                        "closedAt": "2020-08-07T20:38:21Z"
                    },
                    {
                        "title": "DeepFool performance issues",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/475",
                        "createdAt": "2020-06-19T12:22:47Z",
                        "closedAt": "2020-06-25T18:53:08Z"
                    },
                    {
                        "title": "Failed import in  art.attacks.evasion.__init__.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/477",
                        "createdAt": "2020-06-22T01:53:18Z",
                        "closedAt": "2020-06-25T18:52:51Z"
                    },
                    {
                        "title": "variation of CLEVER score",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/478",
                        "createdAt": "2020-06-22T05:30:45Z",
                        "closedAt": "2020-08-07T20:38:50Z"
                    },
                    {
                        "title": "Adversarial Attacks failing when y is not none",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/483",
                        "createdAt": "2020-06-24T19:08:54Z",
                        "closedAt": "2020-06-24T22:48:46Z"
                    },
                    {
                        "title": "Pytorch eval mode",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/484",
                        "createdAt": "2020-06-25T01:24:47Z",
                        "closedAt": "2020-08-07T20:40:23Z"
                    },
                    {
                        "title": "Wrong backward pass in chaining preprocessing defenses",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/485",
                        "createdAt": "2020-06-26T16:18:02Z",
                        "closedAt": "2020-09-20T22:56:14Z"
                    },
                    {
                        "title": "Question about discrete data",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/486",
                        "createdAt": "2020-06-27T15:36:10Z",
                        "closedAt": "2020-08-07T20:40:44Z"
                    },
                    {
                        "title": "Add progress bars to art.defences.trainer",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/488",
                        "createdAt": "2020-07-03T15:13:36Z",
                        "closedAt": "2020-09-20T22:56:50Z"
                    },
                    {
                        "title": "Implement Brendel and Bethge attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/489",
                        "createdAt": "2020-07-03T15:17:29Z",
                        "closedAt": "2020-12-01T12:15:09Z"
                    },
                    {
                        "title": "Add support for targeted attacks in art.attacks.evasion.AutoAttack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/490",
                        "createdAt": "2020-07-03T15:22:50Z",
                        "closedAt": "2020-09-20T22:56:27Z"
                    },
                    {
                        "title": "art.estimators not found",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/492",
                        "createdAt": "2020-07-08T14:34:35Z",
                        "closedAt": "2020-07-20T14:22:13Z"
                    },
                    {
                        "title": "Introduce targeted as property in base class EvasionAttack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/496",
                        "createdAt": "2020-07-16T20:21:49Z",
                        "closedAt": "2020-09-20T22:56:21Z"
                    },
                    {
                        "title": "RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/497",
                        "createdAt": "2020-07-17T02:50:37Z",
                        "closedAt": "2020-08-07T20:37:32Z"
                    },
                    {
                        "title": "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/498",
                        "createdAt": "2020-07-17T18:55:10Z",
                        "closedAt": "2020-08-07T20:39:46Z"
                    },
                    {
                        "title": "cannot import name 'CLIP_VALUES_TYPE'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/501",
                        "createdAt": "2020-07-21T06:13:18Z",
                        "closedAt": "2020-07-21T13:44:23Z"
                    },
                    {
                        "title": "AttributeError: 'DecisionTreeClassifier' object has no attribute 'get_trees'  in  RobustnessVerificationTreeModelsCliqueMethod",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/502",
                        "createdAt": "2020-07-21T13:23:25Z",
                        "closedAt": "2020-08-07T20:39:12Z"
                    },
                    {
                        "title": "Add Neural Cleanse defense for backdoor attacks in NN",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/503",
                        "createdAt": "2020-07-21T18:34:51Z",
                        "closedAt": "2020-09-19T17:24:36Z"
                    },
                    {
                        "title": "Adding examples for computing robustness metrics",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/504",
                        "createdAt": "2020-07-21T19:45:53Z",
                        "closedAt": null
                    },
                    {
                        "title": "FBF example script is yielding very low accuracies",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/505",
                        "createdAt": "2020-07-22T13:45:15Z",
                        "closedAt": "2020-08-07T20:37:47Z"
                    },
                    {
                        "title": "Success criteria in AutoAttack in ART 1.3.1 negatively influenced by numerical accuracy",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/507",
                        "createdAt": "2020-07-23T00:28:38Z",
                        "closedAt": "2020-08-07T20:38:00Z"
                    },
                    {
                        "title": "Adversarial evasion attacks on regression",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/509",
                        "createdAt": "2020-07-23T04:31:17Z",
                        "closedAt": null
                    },
                    {
                        "title": "Targeted APGD in ART 1.3.1 selecting successful examples incorrectly",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/512",
                        "createdAt": "2020-07-24T19:17:26Z",
                        "closedAt": "2020-08-07T20:33:04Z"
                    },
                    {
                        "title": "Inputs for the attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/514",
                        "createdAt": "2020-07-29T10:59:59Z",
                        "closedAt": "2020-12-01T12:32:05Z"
                    },
                    {
                        "title": "Poison Detection - Activation Defense with Keras Generator",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/515",
                        "createdAt": "2020-07-29T17:20:37Z",
                        "closedAt": null
                    },
                    {
                        "title": "Not able to execute pixel defend",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/516",
                        "createdAt": "2020-08-01T13:14:08Z",
                        "closedAt": "2021-07-12T16:17:15Z"
                    },
                    {
                        "title": "Parallelize attack on GPU",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/517",
                        "createdAt": "2020-08-03T09:40:56Z",
                        "closedAt": "2020-08-21T20:47:05Z"
                    },
                    {
                        "title": "PGD for PyTorch fails with arrays as clip_values",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/518",
                        "createdAt": "2020-08-04T14:05:06Z",
                        "closedAt": "2020-08-07T20:36:24Z"
                    },
                    {
                        "title": "UniversalPerturbation raises an AttributeError importing ProjectedGradientDescent",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/519",
                        "createdAt": "2020-08-04T14:14:19Z",
                        "closedAt": "2020-08-07T20:36:04Z"
                    },
                    {
                        "title": "Provide support for true labels in UniversalPerturbation.generate",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/520",
                        "createdAt": "2020-08-04T14:25:31Z",
                        "closedAt": "2020-08-07T20:35:52Z"
                    },
                    {
                        "title": "Dimension mismatch errors when running the Wasserstein attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/522",
                        "createdAt": "2020-08-05T07:57:29Z",
                        "closedAt": "2020-08-07T20:37:05Z"
                    },
                    {
                        "title": "Backdoor embedding attack ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/524",
                        "createdAt": "2020-08-06T16:37:21Z",
                        "closedAt": "2020-09-11T16:32:39Z"
                    },
                    {
                        "title": "Binary classification error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/535",
                        "createdAt": "2020-08-09T20:00:24Z",
                        "closedAt": null
                    },
                    {
                        "title": "Out of Bounds Error in Square Attack when True labels are not Provided",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/536",
                        "createdAt": "2020-08-09T21:13:52Z",
                        "closedAt": "2020-08-21T20:46:27Z"
                    },
                    {
                        "title": "The application_object_detection.py in examples doesn't work!",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/548",
                        "createdAt": "2020-08-13T07:43:32Z",
                        "closedAt": "2020-12-01T12:30:18Z"
                    },
                    {
                        "title": "Can't find an example for using Adversarial Patch!",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/553",
                        "createdAt": "2020-08-14T06:50:13Z",
                        "closedAt": "2020-12-01T12:30:32Z"
                    },
                    {
                        "title": "Dockerfile Is not always up to date with dependencies in requirements.txt file",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/554",
                        "createdAt": "2020-08-14T10:37:57Z",
                        "closedAt": "2020-08-21T20:46:07Z"
                    },
                    {
                        "title": "Check estimator configurations",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/565",
                        "createdAt": "2020-08-19T16:21:38Z",
                        "closedAt": "2020-12-01T12:15:54Z"
                    },
                    {
                        "title": "estimator applying preprocessing standardisation to pytorch model causes broadcasting error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/569",
                        "createdAt": "2020-08-21T22:14:29Z",
                        "closedAt": "2020-08-24T22:30:52Z"
                    },
                    {
                        "title": "Move all Evasion tests to the new ART Testing Framework and make them framework independent",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/580",
                        "createdAt": "2020-08-31T14:18:02Z",
                        "closedAt": null
                    },
                    {
                        "title": "Mismatched dtypes when using FGM-with-random-init and estimator clip_values",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/582",
                        "createdAt": "2020-08-31T22:59:01Z",
                        "closedAt": "2020-11-04T14:54:08Z"
                    },
                    {
                        "title": "ThermometerEncoding thermometer_grad dimension mismatch when channels_first is True",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/585",
                        "createdAt": "2020-09-03T15:08:55Z",
                        "closedAt": "2020-09-20T22:55:43Z"
                    },
                    {
                        "title": "Less strict dependencies",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/587",
                        "createdAt": "2020-09-04T08:12:34Z",
                        "closedAt": "2020-12-01T12:17:10Z"
                    },
                    {
                        "title": "Many new preprocessor tests do not follow ART test conventions",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/590",
                        "createdAt": "2020-09-07T14:25:53Z",
                        "closedAt": "2020-12-01T12:31:01Z"
                    },
                    {
                        "title": "Investigate bad performance in Spectrum Signatures poisoning defense ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/593",
                        "createdAt": "2020-09-10T17:39:27Z",
                        "closedAt": "2020-11-20T16:50:07Z"
                    },
                    {
                        "title": "Implement Label-Only Membership Inference Attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/595",
                        "createdAt": "2020-09-11T20:25:35Z",
                        "closedAt": "2020-12-01T12:29:56Z"
                    },
                    {
                        "title": "new deep learning tests need to be integrated in test_deeplearning_common.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/597",
                        "createdAt": "2020-09-14T15:01:01Z",
                        "closedAt": "2020-09-14T15:16:39Z"
                    },
                    {
                        "title": "Impulse response filtering for sequential inputs",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/600",
                        "createdAt": "2020-09-15T14:16:23Z",
                        "closedAt": "2020-12-01T12:15:19Z"
                    },
                    {
                        "title": "Investigate cost matrix calculation in Wasserstein evasion attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/602",
                        "createdAt": "2020-09-16T21:31:15Z",
                        "closedAt": "2020-12-01T12:16:21Z"
                    },
                    {
                        "title": "ModuleNotFoundError: No module named `kornia` in ART 1.4.0",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/607",
                        "createdAt": "2020-09-21T10:13:06Z",
                        "closedAt": "2020-10-02T20:16:50Z"
                    },
                    {
                        "title": "Confusing number of iterations in ProjectedGradientDescentTensorFlowV2 progress bar in ART 1.4.0",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/608",
                        "createdAt": "2020-09-21T10:15:14Z",
                        "closedAt": "2020-10-02T20:15:51Z"
                    },
                    {
                        "title": "Not all tools accessible from `import art` in ART 1.4.0",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/609",
                        "createdAt": "2020-09-21T10:21:48Z",
                        "closedAt": "2020-10-02T20:15:43Z"
                    },
                    {
                        "title": "Docs build does not get triggered",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/610",
                        "createdAt": "2020-09-21T12:11:43Z",
                        "closedAt": "2020-09-23T20:28:43Z"
                    },
                    {
                        "title": "Question: Is parallel attack support a useful feature within ART?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/618",
                        "createdAt": "2020-09-25T13:22:05Z",
                        "closedAt": null
                    },
                    {
                        "title": "Create module for Evaluations",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/622",
                        "createdAt": "2020-09-28T17:37:34Z",
                        "closedAt": "2020-12-01T12:15:02Z"
                    },
                    {
                        "title": "Support for attack budget eps per feature",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/623",
                        "createdAt": "2020-09-28T18:14:29Z",
                        "closedAt": "2020-12-01T12:14:54Z"
                    },
                    {
                        "title": "Implement support for attack mask in HopSkipJump",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/624",
                        "createdAt": "2020-09-28T18:21:37Z",
                        "closedAt": "2020-12-01T12:14:58Z"
                    },
                    {
                        "title": "Generalise framework-specific preprocessing to include estimator.preprocessing (standardisation)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/625",
                        "createdAt": "2020-09-28T19:07:22Z",
                        "closedAt": "2020-12-01T12:16:55Z"
                    },
                    {
                        "title": "loss function in carlini.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/627",
                        "createdAt": "2020-09-28T23:52:17Z",
                        "closedAt": "2020-11-04T14:51:59Z"
                    },
                    {
                        "title": "Create a notebook for DeepSpeech estimator and ASR attack.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/628",
                        "createdAt": "2020-09-30T12:16:01Z",
                        "closedAt": "2020-10-02T20:18:32Z"
                    },
                    {
                        "title": "Parsing self.is_tensorflow from KerasClassifier input type",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/630",
                        "createdAt": "2020-09-30T20:47:19Z",
                        "closedAt": "2020-10-02T20:15:37Z"
                    },
                    {
                        "title": "ModuleNotFoundError: No module named 'art.defences.detector.poisoning'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/632",
                        "createdAt": "2020-10-01T10:18:51Z",
                        "closedAt": "2020-10-02T20:15:28Z"
                    },
                    {
                        "title": "Create a Verification that each Test is run at least in 1 framework",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/633",
                        "createdAt": "2020-10-01T14:59:27Z",
                        "closedAt": null
                    },
                    {
                        "title": "Allow Armory users to turn off progress bars in attacks/defenses",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/640",
                        "createdAt": "2020-10-02T20:53:59Z",
                        "closedAt": "2020-11-04T14:45:56Z"
                    },
                    {
                        "title": "Auto PGD doesn't not support Kerasclassifier wrapper? ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/643",
                        "createdAt": "2020-10-07T03:00:57Z",
                        "closedAt": "2020-11-04T14:48:16Z"
                    },
                    {
                        "title": "SquareAttack is not instantiated with \"batch_size\". Causes AttributeError.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/645",
                        "createdAt": "2020-10-07T15:15:28Z",
                        "closedAt": "2020-11-04T14:46:05Z"
                    },
                    {
                        "title": "Links broken on the Get-Started.md page",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/649",
                        "createdAt": "2020-10-08T18:00:30Z",
                        "closedAt": "2020-11-04T14:51:44Z"
                    },
                    {
                        "title": "Implement model-specific estimator for TensorFlow SSD object detection models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/650",
                        "createdAt": "2020-10-08T19:59:13Z",
                        "closedAt": null
                    }
                ],
                "pageInfo": {
                    "endCursor": "Y3Vyc29yOnYyOpHOKsYQvA==",
                    "hasNextPage": true
                }
            }
        }
    }
}