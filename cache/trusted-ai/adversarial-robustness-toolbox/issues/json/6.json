{
    "data": {
        "repository": {
            "issues": {
                "totalCount": 802,
                "nodes": [
                    {
                        "title": "Bug/Typo in HopSkipJump Attack Notebook",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1111",
                        "createdAt": "2021-05-17T00:33:30Z",
                        "closedAt": "2021-09-25T23:40:24Z"
                    },
                    {
                        "title": "carlini.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1117",
                        "createdAt": "2021-05-19T19:42:24Z",
                        "closedAt": "2021-06-15T22:22:15Z"
                    },
                    {
                        "title": "Enable using ground-truth y for ART object detectors' loss_gradient()",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1119",
                        "createdAt": "2021-05-19T20:40:36Z",
                        "closedAt": "2021-05-20T22:58:58Z"
                    },
                    {
                        "title": "Attack Pytorch model",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1121",
                        "createdAt": "2021-05-20T20:09:19Z",
                        "closedAt": "2021-05-26T19:01:06Z"
                    },
                    {
                        "title": "The LFilterPyTorch does not work with torch > 1.6 and torchaudio > 0.6",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1123",
                        "createdAt": "2021-05-21T12:40:15Z",
                        "closedAt": null
                    },
                    {
                        "title": "Got error prompt while introducing mini-batch into HopSkipJump ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1130",
                        "createdAt": "2021-05-27T09:36:43Z",
                        "closedAt": "2021-06-15T22:22:43Z"
                    },
                    {
                        "title": "Literature Basis for the MembershipInference Blackbox Attack?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1131",
                        "createdAt": "2021-05-27T10:01:07Z",
                        "closedAt": "2021-06-01T07:25:01Z"
                    },
                    {
                        "title": "Support for user-defined adversarial criteria in black-box evasion attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1134",
                        "createdAt": "2021-05-31T15:55:57Z",
                        "closedAt": null
                    },
                    {
                        "title": "Implement support for non-torch.nn.Sequential model types in PyTorchClassifier.get_layers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1135",
                        "createdAt": "2021-05-31T15:59:32Z",
                        "closedAt": null
                    },
                    {
                        "title": "in-place gradient runtime errors for object detection attack examples",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1136",
                        "createdAt": "2021-06-01T11:33:15Z",
                        "closedAt": "2021-06-15T22:21:10Z"
                    },
                    {
                        "title": "HopSkipJumpAttack notebook with TF 2.2.0",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1137",
                        "createdAt": "2021-06-01T12:37:37Z",
                        "closedAt": "2021-06-16T15:08:30Z"
                    },
                    {
                        "title": "isoxai",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1140",
                        "createdAt": "2021-06-02T10:18:21Z",
                        "closedAt": "2021-06-02T10:51:08Z"
                    },
                    {
                        "title": "Test fixture for functional Keras image classifier never used",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1143",
                        "createdAt": "2021-06-04T22:29:50Z",
                        "closedAt": null
                    },
                    {
                        "title": "Clever score parameters",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1144",
                        "createdAt": "2021-06-07T17:12:40Z",
                        "closedAt": "2021-07-12T14:35:24Z"
                    },
                    {
                        "title": "Implement EoT for rotation in object detection",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1145",
                        "createdAt": "2021-06-07T19:22:51Z",
                        "closedAt": null
                    },
                    {
                        "title": "SKlearn classifiers and FastGradientMethod",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1148",
                        "createdAt": "2021-06-10T16:52:02Z",
                        "closedAt": "2021-06-10T21:38:37Z"
                    },
                    {
                        "title": "auto_projected_gradient_descent.py ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1150",
                        "createdAt": "2021-06-11T20:24:48Z",
                        "closedAt": "2021-07-12T14:35:36Z"
                    },
                    {
                        "title": "_apply_preprocessing",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1151",
                        "createdAt": "2021-06-14T02:49:04Z",
                        "closedAt": "2021-07-12T14:35:50Z"
                    },
                    {
                        "title": "PyTorchEstimator with non-PyTorch preprocessor does not compute gradient correctly",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1155",
                        "createdAt": "2021-06-14T22:05:31Z",
                        "closedAt": "2021-07-12T14:36:13Z"
                    },
                    {
                        "title": "SimBA attack parameters for CIFAR 10",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1157",
                        "createdAt": "2021-06-15T07:33:44Z",
                        "closedAt": "2021-07-12T14:36:00Z"
                    },
                    {
                        "title": "The Imperceptible ASR Pytorch produces Nan loss when computing with batch_size greater than 1",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1158",
                        "createdAt": "2021-06-15T13:23:49Z",
                        "closedAt": "2021-07-12T12:29:54Z"
                    },
                    {
                        "title": "FailedPreconditionError",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1159",
                        "createdAt": "2021-06-16T03:22:30Z",
                        "closedAt": "2021-07-12T12:32:18Z"
                    },
                    {
                        "title": "[MembershipInferenceBlackBox] Why does the attack shuffles the inputed data?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1165",
                        "createdAt": "2021-06-16T11:12:09Z",
                        "closedAt": "2021-07-12T12:30:08Z"
                    },
                    {
                        "title": "Implement Boundary Attack from Li and Zhang",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1167",
                        "createdAt": "2021-06-16T14:10:59Z",
                        "closedAt": "2021-09-25T23:36:32Z"
                    },
                    {
                        "title": "Documentation for the art.attacks and art.metrics are missing",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1168",
                        "createdAt": "2021-06-16T19:38:41Z",
                        "closedAt": "2021-06-16T21:06:54Z"
                    },
                    {
                        "title": "Value Error for TensorFlowV2Classifier in extraction attack running on MNIST data",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1172",
                        "createdAt": "2021-06-17T08:06:11Z",
                        "closedAt": "2021-06-30T01:33:52Z"
                    },
                    {
                        "title": "Application of Preprocessor does not account for apply_fit and apply_predict",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1174",
                        "createdAt": "2021-06-17T20:57:02Z",
                        "closedAt": "2021-07-12T12:34:10Z"
                    },
                    {
                        "title": "KerasClassifier model produces poor performance",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1176",
                        "createdAt": "2021-06-17T23:06:54Z",
                        "closedAt": "2021-07-12T14:36:28Z"
                    },
                    {
                        "title": "feature_adversaries_tensorflow.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1177",
                        "createdAt": "2021-06-18T16:56:14Z",
                        "closedAt": "2021-09-25T23:39:59Z"
                    },
                    {
                        "title": "Running get_started_keras.py fails",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1180",
                        "createdAt": "2021-06-21T11:08:25Z",
                        "closedAt": "2021-07-12T12:37:48Z"
                    },
                    {
                        "title": "PixelDefend uses function that is not implemented",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1183",
                        "createdAt": "2021-06-21T19:03:44Z",
                        "closedAt": "2021-06-22T22:24:26Z"
                    },
                    {
                        "title": "Examples for Object Detection",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1184",
                        "createdAt": "2021-06-22T17:02:34Z",
                        "closedAt": "2021-06-23T11:44:22Z"
                    },
                    {
                        "title": "feature_adversaries_numpy.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1185",
                        "createdAt": "2021-06-22T19:57:29Z",
                        "closedAt": "2021-08-30T23:52:19Z"
                    },
                    {
                        "title": "Spectral Signature Defense Bug When Testing on CNN trained on CIFAR10",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1188",
                        "createdAt": "2021-06-23T23:14:13Z",
                        "closedAt": "2021-09-25T23:41:06Z"
                    },
                    {
                        "title": "save function in estimators.classification.TensorFlowV2Classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1190",
                        "createdAt": "2021-06-25T08:00:42Z",
                        "closedAt": "2021-07-12T16:13:13Z"
                    },
                    {
                        "title": "add non-framework install option",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1191",
                        "createdAt": "2021-06-25T17:34:15Z",
                        "closedAt": "2021-07-12T12:37:39Z"
                    },
                    {
                        "title": "Replace art.classifiers and art.wrappers with art.estimators",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1195",
                        "createdAt": "2021-06-28T12:34:42Z",
                        "closedAt": "2021-09-25T23:36:39Z"
                    },
                    {
                        "title": "General estimator for object detectors in PyTorch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1196",
                        "createdAt": "2021-06-28T12:47:04Z",
                        "closedAt": "2021-09-25T23:36:43Z"
                    },
                    {
                        "title": "Incorrect import statements in examples/mnist_cnn_fgsm.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1199",
                        "createdAt": "2021-06-30T04:27:46Z",
                        "closedAt": "2021-06-30T12:40:31Z"
                    },
                    {
                        "title": "Intel(R) Extension for Scikit-learn for Scikit-learn estimators from ART",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1200",
                        "createdAt": "2021-06-30T14:03:44Z",
                        "closedAt": null
                    },
                    {
                        "title": "Support normalized audio input in MP3 compression defense",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1202",
                        "createdAt": "2021-06-30T16:10:00Z",
                        "closedAt": "2021-07-12T12:37:33Z"
                    },
                    {
                        "title": "Black-box attack SPSA",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1203",
                        "createdAt": "2021-06-30T18:31:57Z",
                        "closedAt": "2021-07-12T16:12:19Z"
                    },
                    {
                        "title": "Using the aliases of builtin types like np.int is deprecated¶",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1204",
                        "createdAt": "2021-07-01T03:45:02Z",
                        "closedAt": "2021-12-18T22:33:16Z"
                    },
                    {
                        "title": "ART for TFLite models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1212",
                        "createdAt": "2021-07-05T21:27:07Z",
                        "closedAt": "2021-07-06T22:40:39Z"
                    },
                    {
                        "title": "Extend BlackBoxClassifier* to accept a tuple of input/labels instead of callable",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1215",
                        "createdAt": "2021-07-06T22:44:30Z",
                        "closedAt": "2021-09-25T23:36:59Z"
                    },
                    {
                        "title": "PyTorchClassifier fit function and fit_generator function give different result.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1217",
                        "createdAt": "2021-07-07T20:32:42Z",
                        "closedAt": "2021-07-12T12:37:12Z"
                    },
                    {
                        "title": "feature_adversaries_tensorflow.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1220",
                        "createdAt": "2021-07-09T14:00:50Z",
                        "closedAt": "2021-09-25T23:39:21Z"
                    },
                    {
                        "title": "Tensors on different devices lead to RuntimeError with PyTorchClassifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1221",
                        "createdAt": "2021-07-09T14:22:11Z",
                        "closedAt": "2021-07-12T12:36:57Z"
                    },
                    {
                        "title": "Examples for tabular data",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1222",
                        "createdAt": "2021-07-09T15:51:32Z",
                        "closedAt": "2021-07-10T03:42:18Z"
                    },
                    {
                        "title": "Generating adversarial examples from a restored model causes examples generation to run endlessly",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1224",
                        "createdAt": "2021-07-09T20:06:25Z",
                        "closedAt": "2021-07-12T14:24:52Z"
                    },
                    {
                        "title": "Empirical Robustness Metric Support for all Evasion attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1226",
                        "createdAt": "2021-07-10T17:02:17Z",
                        "closedAt": "2021-07-12T14:07:06Z"
                    },
                    {
                        "title": "Is there any example code for attacking the speech recognition models (DeepSpeech/Lingvo)?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1232",
                        "createdAt": "2021-07-13T05:23:20Z",
                        "closedAt": "2021-07-13T09:46:21Z"
                    },
                    {
                        "title": "Number of times model was queried by black-box evasion attacks such as Boundary or HopSkipJump?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1238",
                        "createdAt": "2021-07-16T18:18:30Z",
                        "closedAt": "2021-07-19T12:08:00Z"
                    },
                    {
                        "title": "Audio classification attacks?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1241",
                        "createdAt": "2021-07-24T03:57:57Z",
                        "closedAt": null
                    },
                    {
                        "title": "image length-width ratio limits in square attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1244",
                        "createdAt": "2021-07-26T16:14:49Z",
                        "closedAt": null
                    },
                    {
                        "title": "PyTorchClassifier.compute_loss() doesn't accept index-based labels",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1245",
                        "createdAt": "2021-07-26T19:37:22Z",
                        "closedAt": "2021-08-30T23:29:15Z"
                    },
                    {
                        "title": "Move decoder_patched.py to contrib",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1251",
                        "createdAt": "2021-07-30T15:35:18Z",
                        "closedAt": "2021-09-25T23:37:03Z"
                    },
                    {
                        "title": "feature_collision_attack.py generates poison instances that are NaN.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1252",
                        "createdAt": "2021-08-01T00:26:46Z",
                        "closedAt": null
                    },
                    {
                        "title": "Exception is raised even if min_epsilon is a positive float in BoundaryAttack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1258",
                        "createdAt": "2021-08-06T00:42:39Z",
                        "closedAt": "2021-08-30T23:29:06Z"
                    },
                    {
                        "title": "Dimension incompatability when using EoT rotation",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1267",
                        "createdAt": "2021-08-13T21:28:45Z",
                        "closedAt": "2021-09-07T13:00:19Z"
                    },
                    {
                        "title": "Link failure problem",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1275",
                        "createdAt": "2021-08-22T06:38:36Z",
                        "closedAt": "2021-08-23T15:11:26Z"
                    },
                    {
                        "title": "Support for transformers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1280",
                        "createdAt": "2021-08-24T04:24:28Z",
                        "closedAt": "2021-08-24T14:22:15Z"
                    },
                    {
                        "title": "About the use of adversarial patch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1283",
                        "createdAt": "2021-08-25T03:48:29Z",
                        "closedAt": "2021-08-25T10:16:40Z"
                    },
                    {
                        "title": "The original image is referenced after transposition",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1289",
                        "createdAt": "2021-08-26T19:42:02Z",
                        "closedAt": "2021-08-30T23:28:56Z"
                    },
                    {
                        "title": "Update notebook adversarial_training_mnist.ipynb",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1298",
                        "createdAt": "2021-09-03T15:09:26Z",
                        "closedAt": null
                    },
                    {
                        "title": "Error in cell 5 in notebooks/detection_adversarial_samples_cifar10.ipynb",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1299",
                        "createdAt": "2021-09-04T23:09:07Z",
                        "closedAt": null
                    },
                    {
                        "title": "TF import overwrite when using tf2 for tf1 support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1303",
                        "createdAt": "2021-09-08T18:57:28Z",
                        "closedAt": null
                    },
                    {
                        "title": "How to load .model and .optimizer file for load pytorch model?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1304",
                        "createdAt": "2021-09-12T03:01:19Z",
                        "closedAt": "2021-09-13T15:28:08Z"
                    },
                    {
                        "title": "Add TensorFlow2 estimator for deep generative models ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1306",
                        "createdAt": "2021-09-13T11:35:49Z",
                        "closedAt": "2022-03-16T15:33:44Z"
                    },
                    {
                        "title": "Implement backdoor attacks for DGMs",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1307",
                        "createdAt": "2021-09-13T11:39:07Z",
                        "closedAt": "2022-03-16T15:33:47Z"
                    },
                    {
                        "title": "Issue of import error when running model inversion attack notebook",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1311",
                        "createdAt": "2021-09-14T18:47:46Z",
                        "closedAt": "2021-09-15T16:02:36Z"
                    },
                    {
                        "title": "Some documents of attacks.evasion are not displayed properly",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1316",
                        "createdAt": "2021-09-21T06:00:38Z",
                        "closedAt": "2021-09-25T23:37:47Z"
                    },
                    {
                        "title": "Inconsistency input shape for AdversarialPatchPyTorch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1324",
                        "createdAt": "2021-09-28T05:56:45Z",
                        "closedAt": "2021-10-18T20:46:47Z"
                    },
                    {
                        "title": "integrate \"indicators of attack failure\" from Pintor et al 2021",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1325",
                        "createdAt": "2021-09-28T15:18:48Z",
                        "closedAt": "2021-12-18T22:35:14Z"
                    },
                    {
                        "title": "Implement Physical Adversarial Textures",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1326",
                        "createdAt": "2021-09-29T11:08:05Z",
                        "closedAt": "2021-12-18T22:33:03Z"
                    },
                    {
                        "title": "Implement Adversarial Laser Beam attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1327",
                        "createdAt": "2021-09-29T11:11:02Z",
                        "closedAt": "2021-12-18T22:33:09Z"
                    },
                    {
                        "title": "Investigate support for JAX",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1328",
                        "createdAt": "2021-09-29T12:26:11Z",
                        "closedAt": "2021-12-18T22:33:30Z"
                    },
                    {
                        "title": "Attach self._patch to images in adversarial_patch_pytorch.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1329",
                        "createdAt": "2021-09-29T12:59:35Z",
                        "closedAt": "2021-09-29T13:31:58Z"
                    },
                    {
                        "title": "ZOOAttack Sucess rate ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1330",
                        "createdAt": "2021-09-29T15:50:10Z",
                        "closedAt": "2021-09-29T19:23:00Z"
                    },
                    {
                        "title": "Implement SIGN-OPT: A Query-Efficient Hard-label Black-box Attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1331",
                        "createdAt": "2021-09-29T19:08:58Z",
                        "closedAt": "2022-07-01T20:35:50Z"
                    },
                    {
                        "title": "check_and_transform_label_format with return_one_hot=True does not one hot encode when nb_classes=2",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1334",
                        "createdAt": "2021-09-30T15:38:42Z",
                        "closedAt": "2021-12-18T22:34:31Z"
                    },
                    {
                        "title": "The result of using the Wasserstein attack is the \"nan\" value.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1338",
                        "createdAt": "2021-10-03T11:45:18Z",
                        "closedAt": "2021-10-03T11:55:12Z"
                    },
                    {
                        "title": "Unable to train classifier with padding=1 using PyTorch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1344",
                        "createdAt": "2021-10-05T20:01:36Z",
                        "closedAt": "2021-10-06T19:39:45Z"
                    },
                    {
                        "title": "Runtime error while running example/application_object_detection.py",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1347",
                        "createdAt": "2021-10-07T01:09:21Z",
                        "closedAt": "2021-10-18T20:47:03Z"
                    },
                    {
                        "title": "TensorflowV2Classifier does not have a save method",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1349",
                        "createdAt": "2021-10-08T18:50:39Z",
                        "closedAt": "2021-10-08T18:53:04Z"
                    },
                    {
                        "title": "NotImplementedError: The current combination of preprocessing types is not supported.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1350",
                        "createdAt": "2021-10-09T22:14:35Z",
                        "closedAt": "2021-10-10T11:12:45Z"
                    },
                    {
                        "title": "Evasion attacks (DeepFool & possibly others) do not support multiple inputs",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1359",
                        "createdAt": "2021-10-15T07:53:09Z",
                        "closedAt": null
                    },
                    {
                        "title": "ShapeShifter Example",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1370",
                        "createdAt": "2021-10-19T18:07:54Z",
                        "closedAt": "2021-10-20T09:56:04Z"
                    },
                    {
                        "title": "Stateful Detection of Black-Box Adversarial Attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1373",
                        "createdAt": "2021-10-20T08:25:41Z",
                        "closedAt": null
                    },
                    {
                        "title": "CarliniLInfMethod differs significantly from the original, resulting in lower attack success rate",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1374",
                        "createdAt": "2021-10-20T08:44:46Z",
                        "closedAt": "2021-12-18T22:33:40Z"
                    },
                    {
                        "title": "Trouble Reproducing the Adversarial Patch Notebook Results",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1382",
                        "createdAt": "2021-10-29T06:49:07Z",
                        "closedAt": "2021-10-29T11:11:53Z"
                    },
                    {
                        "title": "Implement Witches’ brew  poisoning attack ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1386",
                        "createdAt": "2021-11-01T19:41:34Z",
                        "closedAt": "2022-03-16T15:33:39Z"
                    },
                    {
                        "title": "Add PyTorch implementation for Poison Frogs poisoning attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1387",
                        "createdAt": "2021-11-01T19:46:29Z",
                        "closedAt": "2022-03-16T15:33:38Z"
                    },
                    {
                        "title": "Implement Hidden Trigger Backdoor Attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1388",
                        "createdAt": "2021-11-01T22:48:39Z",
                        "closedAt": "2022-03-16T15:33:42Z"
                    },
                    {
                        "title": "Implement ensemble defense for poisoning ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1389",
                        "createdAt": "2021-11-01T22:50:51Z",
                        "closedAt": "2021-12-18T22:33:56Z"
                    },
                    {
                        "title": "Implement poison-specific adv. training",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1390",
                        "createdAt": "2021-11-01T22:52:52Z",
                        "closedAt": null
                    },
                    {
                        "title": "Poisoning defense: modified adv. training  ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1391",
                        "createdAt": "2021-11-01T22:56:20Z",
                        "closedAt": null
                    },
                    {
                        "title": "Implement sleeper agent ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1392",
                        "createdAt": "2021-11-01T22:58:16Z",
                        "closedAt": "2022-07-01T20:35:38Z"
                    },
                    {
                        "title": "Update learning rate of notebook attack_adversarial_patch_TensorFlowV2.ipynb",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1393",
                        "createdAt": "2021-11-02T00:11:56Z",
                        "closedAt": null
                    },
                    {
                        "title": "Problem with Defenses (PyTorch)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/1401",
                        "createdAt": "2021-11-12T16:08:26Z",
                        "closedAt": "2021-11-12T23:19:03Z"
                    }
                ],
                "pageInfo": {
                    "endCursor": "Y3Vyc29yOnYyOpHOPrYlwA==",
                    "hasNextPage": true
                }
            }
        }
    }
}