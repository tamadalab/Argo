{
    "data": {
        "repository": {
            "issues": {
                "totalCount": 802,
                "nodes": [
                    {
                        "title": "categorical feature support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/199",
                        "createdAt": "2019-11-04T11:36:31Z",
                        "closedAt": null
                    },
                    {
                        "title": "Slack invite is stale",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/203",
                        "createdAt": "2019-11-06T03:49:23Z",
                        "closedAt": "2019-11-06T11:13:35Z"
                    },
                    {
                        "title": "Possible bug in Fast Gradient Method (minimal variant)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/204",
                        "createdAt": "2019-11-06T11:44:09Z",
                        "closedAt": "2020-01-08T01:22:35Z"
                    },
                    {
                        "title": "Support for Pandas Dataframes and Set Preprocessing to None",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/205",
                        "createdAt": "2019-11-08T20:03:59Z",
                        "closedAt": "2020-03-15T20:05:10Z"
                    },
                    {
                        "title": "convert perturb into sphere in boundary attack.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/207",
                        "createdAt": "2019-11-11T03:03:14Z",
                        "closedAt": "2020-01-08T01:26:27Z"
                    },
                    {
                        "title": "HCLU bug",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/208",
                        "createdAt": "2019-11-11T17:44:03Z",
                        "closedAt": "2020-01-06T13:28:40Z"
                    },
                    {
                        "title": "The paper of Attack HopSkipJump",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/209",
                        "createdAt": "2019-11-12T10:59:10Z",
                        "closedAt": "2019-11-14T07:20:28Z"
                    },
                    {
                        "title": "Add KubeFlow component for using ART to check robustness of ML models",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/210",
                        "createdAt": "2019-11-12T11:03:06Z",
                        "closedAt": "2020-06-15T20:47:05Z"
                    },
                    {
                        "title": "EnsembleClassifier not receiving `raw` parameter from attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/214",
                        "createdAt": "2019-11-13T23:38:50Z",
                        "closedAt": "2019-11-20T21:52:00Z"
                    },
                    {
                        "title": "Implement Functionally Equivalent Extraction Attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/216",
                        "createdAt": "2019-11-14T22:43:29Z",
                        "closedAt": "2020-01-08T01:26:59Z"
                    },
                    {
                        "title": "Which attacks have support for multi label in multiclass problem?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/218",
                        "createdAt": "2019-11-15T10:51:25Z",
                        "closedAt": "2020-02-26T23:22:33Z"
                    },
                    {
                        "title": "Deepfool does not work well.",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/219",
                        "createdAt": "2019-11-16T06:16:23Z",
                        "closedAt": "2020-01-08T01:26:40Z"
                    },
                    {
                        "title": "Are these methods suitable for semantic segmentation tasks and 3d images?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/220",
                        "createdAt": "2019-11-16T09:36:17Z",
                        "closedAt": "2019-11-21T01:54:09Z"
                    },
                    {
                        "title": "Keras callback support",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/221",
                        "createdAt": "2019-11-18T10:51:57Z",
                        "closedAt": null
                    },
                    {
                        "title": "Cannot import name 'SklearnClassifier'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/222",
                        "createdAt": "2019-11-20T21:29:56Z",
                        "closedAt": "2019-11-21T17:35:50Z"
                    },
                    {
                        "title": "Add new check to EnsembleClassifier and its classifiers for identical channel_index",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/223",
                        "createdAt": "2019-11-20T21:48:07Z",
                        "closedAt": "2020-01-08T01:27:29Z"
                    },
                    {
                        "title": "Check for incompatible numerical data type in input standardisation of classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/224",
                        "createdAt": "2019-11-26T20:48:26Z",
                        "closedAt": "2020-01-08T01:27:14Z"
                    },
                    {
                        "title": "Investigate logging output for tests",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/227",
                        "createdAt": "2019-11-27T10:28:04Z",
                        "closedAt": "2020-03-15T20:02:58Z"
                    },
                    {
                        "title": "Implement copycat cnn attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/229",
                        "createdAt": "2019-12-04T13:50:43Z",
                        "closedAt": "2020-01-08T01:21:50Z"
                    },
                    {
                        "title": "Implement the Knockoff Nets attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/230",
                        "createdAt": "2019-12-04T13:52:30Z",
                        "closedAt": "2020-03-15T20:00:57Z"
                    },
                    {
                        "title": "Implement defences against model extraction attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/233",
                        "createdAt": "2019-12-06T14:03:03Z",
                        "closedAt": "2020-01-08T01:22:49Z"
                    },
                    {
                        "title": "Enable import of full ART package",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/235",
                        "createdAt": "2019-12-08T16:30:48Z",
                        "closedAt": "2019-12-26T23:31:09Z"
                    },
                    {
                        "title": "Add version to ART package",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/236",
                        "createdAt": "2019-12-08T16:31:12Z",
                        "closedAt": "2019-12-13T03:44:15Z"
                    },
                    {
                        "title": "[1.1.0 Dev Branch] Significantly increased time to wrap Keras model in Keras >2.3 ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/237",
                        "createdAt": "2019-12-08T16:31:27Z",
                        "closedAt": "2019-12-12T01:14:08Z"
                    },
                    {
                        "title": "Support for TF2.x Eager Execution",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/238",
                        "createdAt": "2019-12-08T16:39:33Z",
                        "closedAt": "2019-12-10T14:27:42Z"
                    },
                    {
                        "title": "KerasClassifier get_activations makes assumption about input shape",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/241",
                        "createdAt": "2019-12-09T17:26:06Z",
                        "closedAt": "2020-01-08T00:06:05Z"
                    },
                    {
                        "title": "Roadmap for Keras and TF2 Wrappers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/243",
                        "createdAt": "2019-12-10T14:27:47Z",
                        "closedAt": "2020-12-01T12:33:40Z"
                    },
                    {
                        "title": "Investigate @tf.function models running as a wrapped classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/245",
                        "createdAt": "2019-12-13T03:46:18Z",
                        "closedAt": "2019-12-27T18:11:37Z"
                    },
                    {
                        "title": " AttributeError: 'TensorFlowV2Classifier' object has no attribute '_input_shape'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/246",
                        "createdAt": "2019-12-14T14:55:16Z",
                        "closedAt": "2020-01-05T20:56:12Z"
                    },
                    {
                        "title": "Any adversarial attack that sustains after resize attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/247",
                        "createdAt": "2019-12-16T11:03:00Z",
                        "closedAt": "2020-03-11T20:37:36Z"
                    },
                    {
                        "title": "Accept soft labels in the fit function of ART classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/251",
                        "createdAt": "2019-12-19T15:32:24Z",
                        "closedAt": "2020-03-15T20:01:14Z"
                    },
                    {
                        "title": "trying AdversarialPatch attack and I get 'tuple' object has no attribute 'dtype' error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/252",
                        "createdAt": "2019-12-25T16:40:26Z",
                        "closedAt": "2020-03-11T20:35:23Z"
                    },
                    {
                        "title": "Missing documentation about SVM attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/253",
                        "createdAt": "2019-12-25T20:41:46Z",
                        "closedAt": "2020-01-08T01:22:10Z"
                    },
                    {
                        "title": "VirtualAdversarialMethod - error - Values smaller than 0.0 or larger than 1.0 have been detected",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/263",
                        "createdAt": "2020-01-14T09:45:22Z",
                        "closedAt": "2020-02-26T23:22:11Z"
                    },
                    {
                        "title": "Extend tests to run all TensorFlow unittests with TensorFlow v2 instead of compatibility mode",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/264",
                        "createdAt": "2020-01-15T13:13:53Z",
                        "closedAt": "2020-03-15T20:01:26Z"
                    },
                    {
                        "title": "Move post-processing defences to defences and integrate with classifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/267",
                        "createdAt": "2020-01-20T21:44:16Z",
                        "closedAt": "2020-03-15T20:01:38Z"
                    },
                    {
                        "title": "PyTorchClassifier preprocessing on Imagenet Images",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/268",
                        "createdAt": "2020-01-23T00:35:29Z",
                        "closedAt": "2021-03-16T17:58:07Z"
                    },
                    {
                        "title": "Refactor unit tests",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/269",
                        "createdAt": "2020-01-27T23:13:15Z",
                        "closedAt": "2020-06-15T20:44:22Z"
                    },
                    {
                        "title": "Refactor unit tests for FGSM, BIM and PGD attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/270",
                        "createdAt": "2020-01-27T23:16:46Z",
                        "closedAt": "2020-03-15T20:01:58Z"
                    },
                    {
                        "title": "Add application example for simple Automatic Speech Recognition (ASR)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/271",
                        "createdAt": "2020-01-27T23:26:32Z",
                        "closedAt": "2020-03-15T20:01:48Z"
                    },
                    {
                        "title": "Extend supported labels and tasks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/272",
                        "createdAt": "2020-01-27T23:30:01Z",
                        "closedAt": "2020-02-26T15:59:47Z"
                    },
                    {
                        "title": "Implement attack for imperceptible, robust and targeted adversarial examples for Automatic Speech Recognition",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/273",
                        "createdAt": "2020-01-28T14:00:54Z",
                        "closedAt": "2020-12-01T12:14:35Z"
                    },
                    {
                        "title": "Implement DPatch: An Adversarial Patch Attack on Object Detectors",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/276",
                        "createdAt": "2020-01-30T21:59:36Z",
                        "closedAt": "2020-06-15T20:44:40Z"
                    },
                    {
                        "title": "Implement ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/277",
                        "createdAt": "2020-01-30T22:00:46Z",
                        "closedAt": "2020-09-20T22:54:38Z"
                    },
                    {
                        "title": "MSE function",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/278",
                        "createdAt": "2020-02-03T14:29:32Z",
                        "closedAt": "2020-06-15T20:45:15Z"
                    },
                    {
                        "title": "Difference in adversarial images and adversarial accuracy across different platforms (Keras Classifier and TensorflowV2 Classifier).",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/279",
                        "createdAt": "2020-02-04T12:33:06Z",
                        "closedAt": "2020-02-08T02:22:31Z"
                    },
                    {
                        "title": "Request for addition of Few Pixel Attack (One Pixel Attack)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/280",
                        "createdAt": "2020-02-04T15:36:09Z",
                        "closedAt": "2020-02-25T10:35:46Z"
                    },
                    {
                        "title": "Request for addition of Threshold Attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/281",
                        "createdAt": "2020-02-04T15:37:30Z",
                        "closedAt": "2020-02-25T10:35:39Z"
                    },
                    {
                        "title": "KerasClassifier does not check input shapes",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/283",
                        "createdAt": "2020-02-05T15:22:57Z",
                        "closedAt": "2020-02-08T02:21:06Z"
                    },
                    {
                        "title": "Boundary attack doesn't support unsquared images",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/288",
                        "createdAt": "2020-02-11T12:11:33Z",
                        "closedAt": "2020-03-15T20:03:08Z"
                    },
                    {
                        "title": "EoT is not accounting for transformations in backward pass",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/289",
                        "createdAt": "2020-02-15T13:27:47Z",
                        "closedAt": "2020-12-01T12:40:27Z"
                    },
                    {
                        "title": "Hard Code of Cuda Device in PyTorchClassifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/290",
                        "createdAt": "2020-02-17T11:13:11Z",
                        "closedAt": "2020-03-15T20:02:10Z"
                    },
                    {
                        "title": "Backdoor Poisoning Attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/292",
                        "createdAt": "2020-02-18T16:41:27Z",
                        "closedAt": "2020-03-15T20:02:44Z"
                    },
                    {
                        "title": "Add API and example for transformation defences",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/293",
                        "createdAt": "2020-02-18T17:38:11Z",
                        "closedAt": "2020-03-15T20:02:22Z"
                    },
                    {
                        "title": "Implement Madry's Protocol as adversarial training example",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/294",
                        "createdAt": "2020-02-18T17:41:43Z",
                        "closedAt": "2020-03-15T20:03:20Z"
                    },
                    {
                        "title": "Randomised Smoothing as Training or Certification",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/295",
                        "createdAt": "2020-02-18T17:45:33Z",
                        "closedAt": "2020-06-15T20:42:35Z"
                    },
                    {
                        "title": "HopSkipJump doesn't support unsquared images",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/297",
                        "createdAt": "2020-02-19T15:44:06Z",
                        "closedAt": "2020-03-15T20:04:39Z"
                    },
                    {
                        "title": "Descriptive names for targeted attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/299",
                        "createdAt": "2020-02-19T17:50:42Z",
                        "closedAt": "2020-12-01T12:33:20Z"
                    },
                    {
                        "title": "Binary Classification with Single Output Neuron",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/306",
                        "createdAt": "2020-02-24T21:42:47Z",
                        "closedAt": "2021-06-15T22:19:48Z"
                    },
                    {
                        "title": "Error in Hop skip jump attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/307",
                        "createdAt": "2020-02-24T23:13:45Z",
                        "closedAt": "2021-06-15T22:20:40Z"
                    },
                    {
                        "title": "Create a new Estimator API",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/308",
                        "createdAt": "2020-02-24T23:41:26Z",
                        "closedAt": "2020-06-15T20:41:51Z"
                    },
                    {
                        "title": "Extend Attack API and optimise implementations ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/309",
                        "createdAt": "2020-02-24T23:56:20Z",
                        "closedAt": "2020-06-15T20:42:53Z"
                    },
                    {
                        "title": "Create new Data API",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/310",
                        "createdAt": "2020-02-25T00:13:42Z",
                        "closedAt": "2020-06-15T20:41:39Z"
                    },
                    {
                        "title": "Create Metric API",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/311",
                        "createdAt": "2020-02-25T00:21:52Z",
                        "closedAt": "2020-06-15T20:41:10Z"
                    },
                    {
                        "title": "RL model cannot apply this toolbox",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/313",
                        "createdAt": "2020-02-26T07:58:22Z",
                        "closedAt": "2020-03-03T00:13:54Z"
                    },
                    {
                        "title": "Implement defence evaluations by Tramèr et al. (2020)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/314",
                        "createdAt": "2020-02-26T12:44:10Z",
                        "closedAt": null
                    },
                    {
                        "title": "Implement Feature Adversaries attack by Sabour et al. (2016)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/315",
                        "createdAt": "2020-02-26T13:08:23Z",
                        "closedAt": "2020-06-15T20:46:41Z"
                    },
                    {
                        "title": "Implement a prototype of the new Estimator API",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/316",
                        "createdAt": "2020-02-26T16:08:04Z",
                        "closedAt": "2020-06-15T20:46:27Z"
                    },
                    {
                        "title": "Base class for blackbox or graybox attacks?",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/317",
                        "createdAt": "2020-02-26T22:21:14Z",
                        "closedAt": "2020-02-27T18:43:49Z"
                    },
                    {
                        "title": "Implement defence evaluation 12 - EMPIR",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/319",
                        "createdAt": "2020-03-01T12:30:26Z",
                        "closedAt": "2020-03-15T20:02:37Z"
                    },
                    {
                        "title": "Add application example for video action recognition",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/321",
                        "createdAt": "2020-03-02T16:26:41Z",
                        "closedAt": "2020-03-15T20:03:28Z"
                    },
                    {
                        "title": "cannot import name 'ClassifierNeuralNetwork'",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/322",
                        "createdAt": "2020-03-04T02:49:20Z",
                        "closedAt": "2020-03-05T02:42:31Z"
                    },
                    {
                        "title": "Check method fit_generator in KerasClassifier",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/323",
                        "createdAt": "2020-03-04T15:31:00Z",
                        "closedAt": "2020-03-15T20:02:51Z"
                    },
                    {
                        "title": "Clean-Label Attacks",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/328",
                        "createdAt": "2020-03-10T22:26:23Z",
                        "closedAt": "2020-06-15T20:43:40Z"
                    },
                    {
                        "title": "run adversarial-robustness-toolbox/examples/get_started_keras.py and get error",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/330",
                        "createdAt": "2020-03-11T18:47:59Z",
                        "closedAt": "2020-04-15T01:04:25Z"
                    },
                    {
                        "title": "Implement Wasserstein Adversarial Examples via Projected Sinkhorn Iterations",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/341",
                        "createdAt": "2020-03-16T17:51:24Z",
                        "closedAt": "2020-06-15T20:45:54Z"
                    },
                    {
                        "title": "Implement Shadow Attack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/342",
                        "createdAt": "2020-03-16T18:04:09Z",
                        "closedAt": "2020-06-15T20:44:59Z"
                    },
                    {
                        "title": "Implement defence evaluation 13 - Temporal Dependency",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/343",
                        "createdAt": "2020-03-16T18:22:55Z",
                        "closedAt": "2021-03-16T17:59:50Z"
                    },
                    {
                        "title": "Investigate performance of Projected Gradient Descent (PGD)",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/344",
                        "createdAt": "2020-03-16T18:29:45Z",
                        "closedAt": "2020-06-15T20:39:54Z"
                    },
                    {
                        "title": "Implement Fast is Better than Free protocol for PyTorch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/345",
                        "createdAt": "2020-03-16T18:32:48Z",
                        "closedAt": "2020-06-15T20:39:28Z"
                    },
                    {
                        "title": "Move unittests of all neural network classifiers to new system",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/346",
                        "createdAt": "2020-03-16T18:42:54Z",
                        "closedAt": "2020-09-20T22:54:54Z"
                    },
                    {
                        "title": "Implement framework-specific version of Adversarial Patch attack - TensorFlow v2",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/347",
                        "createdAt": "2020-03-16T20:50:01Z",
                        "closedAt": "2020-06-15T20:38:48Z"
                    },
                    {
                        "title": "Possible Memory Leak",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/348",
                        "createdAt": "2020-03-19T17:22:01Z",
                        "closedAt": "2020-03-26T16:32:34Z"
                    },
                    {
                        "title": "Incorporate DefenceGAN as part of the ART Framework",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/351",
                        "createdAt": "2020-03-24T14:44:31Z",
                        "closedAt": "2020-06-15T20:44:02Z"
                    },
                    {
                        "title": "Carlini Wagner attack does not preturb a lot of the samples",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/352",
                        "createdAt": "2020-03-28T06:57:10Z",
                        "closedAt": "2020-04-28T11:31:57Z"
                    },
                    {
                        "title": "Implement adversarial attacks for optical flow-based action recognition classifiers",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/353",
                        "createdAt": "2020-03-30T11:30:45Z",
                        "closedAt": "2020-06-15T20:43:28Z"
                    },
                    {
                        "title": "PGD attack with a MXNet classifier on a GPU fails",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/355",
                        "createdAt": "2020-04-01T12:49:40Z",
                        "closedAt": "2020-06-15T20:42:24Z"
                    },
                    {
                        "title": "[question] pytorch training",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/359",
                        "createdAt": "2020-04-05T16:47:26Z",
                        "closedAt": "2020-04-10T11:32:55Z"
                    },
                    {
                        "title": "Add type hints to ART",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/360",
                        "createdAt": "2020-04-06T20:20:00Z",
                        "closedAt": "2020-06-15T20:37:12Z"
                    },
                    {
                        "title": "Implement evasion attack AutoAttack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/365",
                        "createdAt": "2020-04-10T14:39:23Z",
                        "closedAt": "2020-06-15T20:42:12Z"
                    },
                    {
                        "title": "Unexpected Dtype Cast Caused By Clipping",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/366",
                        "createdAt": "2020-04-12T09:39:39Z",
                        "closedAt": "2020-05-06T02:21:25Z"
                    },
                    {
                        "title": "High adversarial accuracy of TensorflowV2Classifier under Fast Gradient Sign Method (compared to KerasClassifier).",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/367",
                        "createdAt": "2020-04-13T10:22:50Z",
                        "closedAt": "2020-04-19T07:50:45Z"
                    },
                    {
                        "title": "Obfuscated/Vanishing Gradient Tests and Warning",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/368",
                        "createdAt": "2020-04-13T15:16:37Z",
                        "closedAt": "2020-06-15T20:42:01Z"
                    },
                    {
                        "title": "Error on PixelAttack and ThresholdAttack",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/369",
                        "createdAt": "2020-04-13T22:04:11Z",
                        "closedAt": "2020-06-15T20:38:13Z"
                    },
                    {
                        "title": "Streamlining ART setup process",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/370",
                        "createdAt": "2020-04-14T16:06:39Z",
                        "closedAt": "2020-06-15T20:40:56Z"
                    },
                    {
                        "title": "Add get_model method to Classifer ",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/371",
                        "createdAt": "2020-04-15T00:25:30Z",
                        "closedAt": "2020-06-15T20:40:46Z"
                    },
                    {
                        "title": "Improve logging for fit_generator on keras and pytorch",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/372",
                        "createdAt": "2020-04-15T00:38:19Z",
                        "closedAt": "2020-06-15T20:40:35Z"
                    },
                    {
                        "title": "Poisoning defense with not in-memory dataset",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/373",
                        "createdAt": "2020-04-15T00:45:35Z",
                        "closedAt": "2020-06-09T15:35:14Z"
                    },
                    {
                        "title": "Ability to apply Preprocessor and Postprocessor after Classifier init",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/374",
                        "createdAt": "2020-04-15T00:51:01Z",
                        "closedAt": "2020-06-15T20:40:25Z"
                    },
                    {
                        "title": "Error changing HopSkipJump to Zoo attack on blackbox tesseract ocr",
                        "url": "https://github.com/Trusted-AI/adversarial-robustness-toolbox/issues/379",
                        "createdAt": "2020-04-18T18:57:35Z",
                        "closedAt": "2020-04-18T19:10:52Z"
                    }
                ],
                "pageInfo": {
                    "endCursor": "Y3Vyc29yOnYyOpHOI-nZCw==",
                    "hasNextPage": true
                }
            }
        }
    }
}